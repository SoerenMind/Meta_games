"""Experiments with functional-form agents."""
import itertools
import math
import typing

import numpy as np
import torch

from metagames import game
from . import agents
from . import losses


def scaled_normal_initializer(rand, num_parameters):
    """Initialize from a normal distribution scaled to give norm near 1."""
    return rand.normal(scale=1 / math.sqrt(num_parameters), size=(num_parameters,))


class PlayerSpecification(typing.NamedTuple):
    """A player specification for an experiment.

    Attributes:
        agent: The player agent. Multiple players may share the same agent.
        initializer: Parameter initializer function.
            Maps (numpy_random_state, num_parameters) -> A numpy array of size (num_parameters,)
        loss: A callable that returns the agent's loss on a game outcome.
        optimizer: The player's optimizer class.
        learning_rate: The players's learning rate.
        step_rate: Number of times the player is updated for each global step.
        name: An optional player name.
    """

    agent: agents.OpenSourceBinaryGameAgent
    initializer: typing.Any = scaled_normal_initializer
    loss: losses.BaseLoss = losses.UtilityLoss
    optimizer: typing.Type[torch.optim.Optimizer] = torch.optim.SGD
    learning_rate: float = None
    step_rate: int = 1
    name: str = None


class _ExperimentPlayer(typing.NamedTuple):
    """An initialized experiment player."""

    spec: PlayerSpecification
    parameters: torch.Tensor
    optimizer: torch.optim.Optimizer


class Experiment:
    """Base experiment runner class."""

    def __init__(self, payoff_matrix, dtype=torch.double):
        self.payoff_matrix = torch.tensor(payoff_matrix)

    def _run_steps(self, player_opponents, max_steps=None):
        """Generator of experiment steps.

        Args:
            player_opponents: A list of (player, opponent_function) pairs.
                An opponent function takes the current step index and
                outputs an iterable of opponent players.
            max_steps: Optional maximum number of steps to run.

        Yields:
            For each step, a dictionary of step statistics.
        """
        if max_steps:
            steps = range(max_steps)
        else:
            steps = itertools.count()

        for step in steps:
            step_statistics = {"player_updates": []}
            for player, opponents in player_opponents:
                player_update_statistics = self._update_player(player, opponents)
                step_statistics["player_updates"].append(player_update_statistics)
            yield step_statistics

    def _initialize_players(self, player_specifications, seed=None):
        """Initialize players from a list of player specifications.

        Args:
            player_specifications: The player speceifications.
                An iterable of _ExperimentPlayer instances.
            seed: Optional player parameter initialization seed.
                The per-player seed depends on this seed and their order in `player_specifications`.
        """
        rand = np.random.RandomState(seed)

        players = []
        for player_spec in player_specifications:
            # Create a per-player random generator to so that player parameters
            # do not depend on the number of random samples generated by other players.
            player_rand = np.random.RandomState(rand.randint(2 ** 32))
            parameters = torch.tensor(
                player_spec.initializer(player_rand, player_spec.agent.num_parameters), requires_grad=True
            )

            optimizer_kwargs = {}
            if player_spec.learning_rate is not None:
                optimizer_kwargs["lr"] = player_spec.learning_rate

            optimizer = player_spec.optimizer([parameters], **optimizer_kwargs)
            players.append(_ExperimentPlayer(spec=player_spec, optimizer=optimizer, parameters=parameters))
        return players

    def play_game(self, agent, parameters, opponent_agent, opponent_parameters):
        """Play a game against an opponent."""
        action_logit = agent(parameters, opponent_parameters)
        opponent_action_logit = opponent_agent(opponent_parameters, parameters)

        action_probability = torch.sigmoid(action_logit)
        opponent_action_probability = torch.sigmoid(opponent_action_logit)
        utility = game.binary_game(self.payoff_matrix, action_probability, opponent_action_probability)
        return {"utility": utility, "action_logit": action_logit, "opponent_action_logit": opponent_action_logit}

    def _play_game_grad(self, agent, parameters, loss_fn, opponent_agent, opponent_parameters):
        """Play against an opponent and update player gradients."""
        results = self.play_game(agent, parameters, opponent_agent, opponent_parameters)
        statistics = {name: _tensor_data(value) for name, value in results.items()}

        loss = loss_fn(**results, parameter_vector=parameters, opponent_parameter_vector=opponent_parameters)

        loss.backward()

        return statistics

    def _update_player(self, player, opponents, update_steps=None):
        """Update a player from plays against a set of opponents.

        Args:
            player: The player to update. An instance of _ExperimentPlayer.
            opponents: The opponents. An iterable of _ExperimentPlayer.
            update_steps: Override the number of gradient descent steps performed.
                By default, uses player.spec.step_rate.
        """
        if update_steps is None:
            update_steps = player.spec.step_rate

        agent = player.spec.agent
        parameters = player.parameters
        optimizer = player.optimizer
        loss_fn = player.spec.loss()

        statistics = []
        for _ in range(update_steps):
            optimizer.zero_grad()

            round_statistics = {"rounds": []}
            for opponent in opponents:
                game_statistics = self._play_game_grad(
                    agent=agent,
                    parameters=parameters,
                    loss_fn=loss_fn,
                    opponent_agent=opponent.spec.agent,
                    opponent_parameters=opponent.parameters,
                )
                round_statistics["rounds"].append({"opponent": opponent.spec, **game_statistics})

            round_statistics["grad_norm"] = _tensor_data(torch.norm(parameters.grad))
            round_statistics["mean_utility"] = np.mean(
                [game_stats["utility"] for game_stats in round_statistics["rounds"]]
            )
            statistics.append(round_statistics)
            optimizer.step()

        return statistics


class SelfPlayExperiment(Experiment):
    """All players play against themselves only."""

    def run_steps(self, player_specifications, self_aware, seed=None, max_steps=None):
        """Generator of player updates.

        Args:
            player_specifications: A list of `PlayerSpecification` describing the players.
                Multiple players may be specificied but it acts as a
                batch of independent players that play only against themselves.
            self_aware: Whether the players are aware that they are playing against themselves.
                If True, gradient flows through the copied opponent parameters.
            seed: Parameter initialization seed.
            max_steps: Maximum number of steps to run.

        """
        players = self._initialize_players(player_specifications, seed=seed)
        if self_aware:
            player_opponents = [(player, (player,)) for player in players]
        else:
            # Note: The detached version is a reference that has the same value as the original
            # parameters, so it is unnecessary to update on every gradient step.
            player_opponents = [
                (player, (player._replace(parameters=player.parameters.detach()),)) for player in players
            ]
        yield from self._run_steps(player_opponents, max_steps=max_steps)

    def run(self, player_specifications, num_steps, self_aware, seed=None):
        data = {"players": player_specifications, "num_steps": num_steps, "self_aware": self_aware, "seed": seed}
        data["steps"] = list(self.run_steps(player_specifications, self_aware, seed=seed, max_steps=num_steps))
        return data


def _tensor_data(tensor):
    """The contents of a torch tensor as a numpy array."""
    return tensor.detach().cpu().numpy()
